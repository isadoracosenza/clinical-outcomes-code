{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215e083-e48d-4b4e-8aa7-fa2efe612533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import expit\n",
    "from plotly import express as ex\n",
    "import plotly.io as pio\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV, SGDClassifier, PassiveAggressiveClassifier, Perceptron\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec5d19-5cbe-4737-a632-b59a8a37d9cb",
   "metadata": {},
   "source": [
    "## Using Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830da962-0f3f-4f74-9b29-c08ad20bfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/X_train_Boruta_REINT30.csv')\n",
    "X_test = pd.read_csv('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/X_test_Boruta_REINT30.csv')\n",
    "\n",
    "X_train.dropna(axis=1, how=\"all\", inplace=True)\n",
    "X_test.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "\n",
    "y_train = np.load('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/y_train_Boruta_REINT30.npy')\n",
    "y_test = np.load('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/y_test_Boruta_REINT30.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d741a-db85-498c-a382-4a539e878e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n",
    "    \"LGBMClassifier\": LGBMClassifier(force_col_wise=True, verbosity=-1),\n",
    "    \"XGBClassifier\": XGBClassifier(eval_metric='logloss'),\n",
    "    \"BaggingClassifier\": BaggingClassifier(),\n",
    "    \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"NuSVC\": NuSVC(probability=True, max_iter=10000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RidgeClassifier\": RidgeClassifier(max_iter=1000),\n",
    "    \"SVC\": SVC(probability=True, max_iter=10000),\n",
    "    \"LinearSVC\": LinearSVC(max_iter=10000),\n",
    "    \"LinearDiscriminantAnalysis\": LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "    \"RidgeClassifierCV\": RidgeClassifierCV(),\n",
    "    \"CalibratedClassifierCV\": CalibratedClassifierCV(cv=3),\n",
    "    \"PassiveAggressiveClassifier\": PassiveAggressiveClassifier(max_iter=1000),\n",
    "    \"LabelSpreading\": LabelSpreading(gamma=0.1, max_iter=1000),\n",
    "    \"LabelPropagation\": LabelPropagation(gamma=0.1, max_iter=1000),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"SGDClassifier\": SGDClassifier(max_iter=1000),\n",
    "    \"Perceptron\": Perceptron(max_iter=1000),\n",
    "    \"NearestCentroid\": NearestCentroid(),\n",
    "    \"ExtraTreeClassifier\": ExtraTreeClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DummyClassifier\": DummyClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ea673-210e-44c1-9604-d0c4b9026df0",
   "metadata": {},
   "source": [
    "Cross Validation com todos os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68811a28-a13b-4858-b546-ce260cb21c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, zero_division=0),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "#models_thresholds = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=7,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy Mean': cv['test_accuracy'].mean(),\n",
    "        'Accuracy Std':  cv['test_accuracy'].std(),\n",
    "        'Precision Mean': cv['test_precision'].mean(),\n",
    "        'Precision Std':  cv['test_precision'].std(),\n",
    "        'Recall Mean': cv['test_recall'].mean(),\n",
    "        'Recall Std':  cv['test_recall'].std(),\n",
    "        'F1 Mean': cv['test_f1'].mean(),\n",
    "        'F1 Std':  cv['test_f1'].std(),\n",
    "        'ROC AUC Mean': cv['test_roc_auc'].mean(),\n",
    "        'ROC AUC Std':  cv['test_roc_auc'].std()\n",
    "    })\n",
    "\n",
    "cross_val = pd.DataFrame(results)\n",
    "cross_val = cross_val.round(2)\n",
    "cross_val = cross_val.sort_values(by=\"F1 Mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31788d22-eff0-4228-b09b-ffd3506395d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val.to_excel('Predictions_CrossVal_Boruta_REINT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd4b34-ca12-4e3d-a3f2-cfff503a6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    trained_models[name] = model  \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_scores = model.decision_function(X_test)\n",
    "        y_prob = expit(y_scores)\n",
    "    else:\n",
    "        y_prob = None\n",
    "        \n",
    "    metrics = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"ROC AUC\": roc_auc_score(y_test, y_prob) if y_prob is not None else None,\n",
    "        \"Specificity\": specificity_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "df_results_test = pd.DataFrame(results).round(2)\n",
    "df_results_sorted = df_results_test.sort_values(by=\"F1 Score\", ascending=False)\n",
    "\n",
    "top5_models = df_results_sorted[\"Model\"].head(5).tolist()\n",
    "\n",
    "for name in top5_models:\n",
    "    model = trained_models[name]\n",
    "    with open(f\"{name}_boruta_reint.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"✅ Modelos salvos:\", top5_models)\n",
    "\n",
    "df_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdf6e0-68a7-467e-92ff-522604267d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test.to_excel('Predictions_test_Boruta_REINT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa1e2a-2b55-4b3d-9009-61517db622f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = ex.scatter(df_results_test, x='ROC AUC', y='F1 Score', color='Model', title=\"Análise Comparativa Boruta — Reinternação: F1 score versus ROC AUC score\")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",      # legenda horizontal\n",
    "        yanchor=\"bottom\",\n",
    "        y=-1,               # coloca embaixo\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe0fd6-a499-4d6e-b488-65536c1544f4",
   "metadata": {},
   "source": [
    "## Using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec807f-74e1-4159-aa35-4acb8baca0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/X_train_REINT30.csv')\n",
    "X_test = pd.read_csv('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/X_test_REINT30.csv')\n",
    "\n",
    "y_train = np.load('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/y_train_REINT30.npy')\n",
    "y_test = np.load('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/y_test_REINT30.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead9757-2554-4de2-92a8-c9326b9abd96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, zero_division=0),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "#models_thresholds = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=7,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy Mean': cv['test_accuracy'].mean(),\n",
    "        'Accuracy Std':  cv['test_accuracy'].std(),\n",
    "        'Precision Mean': cv['test_precision'].mean(),\n",
    "        'Precision Std':  cv['test_precision'].std(),\n",
    "        'Recall Mean': cv['test_recall'].mean(),\n",
    "        'Recall Std':  cv['test_recall'].std(),\n",
    "        'F1 Mean': cv['test_f1'].mean(),\n",
    "        'F1 Std':  cv['test_f1'].std(),\n",
    "        'ROC AUC Mean': cv['test_roc_auc'].mean(),\n",
    "        'ROC AUC Std':  cv['test_roc_auc'].std()\n",
    "    })\n",
    "\n",
    "cross_val = pd.DataFrame(results)\n",
    "cross_val = cross_val.round(2)\n",
    "cross_val = cross_val.sort_values(by=\"F1 Mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deccd48-7284-44c5-8a63-d82b3cc47e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val.to_excel('Predictions_CrossVal_allFeatures_REINT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d35e4d-dcb0-4037-8785-e6e50fc64800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    trained_models[name] = model  \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_scores = model.decision_function(X_test)\n",
    "        y_prob = expit(y_scores)\n",
    "    else:\n",
    "        y_prob = None\n",
    "        \n",
    "    metrics = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"ROC AUC\": roc_auc_score(y_test, y_prob) if y_prob is not None else None,\n",
    "        \"Specificity\": specificity_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "df_results_test = pd.DataFrame(results).round(2)\n",
    "df_results_sorted = df_results_test.sort_values(by=\"F1 Score\", ascending=False)\n",
    "\n",
    "top5_models = df_results_sorted[\"Model\"].head(5).tolist()\n",
    "\n",
    "for name in top5_models:\n",
    "    model = trained_models[name]\n",
    "    with open(f\"{name}_allfeatures_reint.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"✅ Modelos salvos:\", top5_models)\n",
    "\n",
    "df_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3251a3-c529-48ea-8432-863cced3c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test.to_excel('Predictions_test_allFeatures_REINT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f94c587-d693-42cb-8aed-b35347995339",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ex.scatter(df_results_test, x='ROC AUC', y='F1 Score', color='Model', title=\"Análise Comparativa (todas as Features) — Reinternação: F1 score versus ROC AUC score\")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",      # legenda horizontal\n",
    "        yanchor=\"bottom\",\n",
    "        y=-1,               # coloca embaixo\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6b74b-1614-40e2-a650-f8b4198e4f68",
   "metadata": {},
   "source": [
    "## Using literature review features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2832f-be0d-4ad9-bf68-1f9a57fae61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/X_train_liter_REINT30.csv')\n",
    "X_test = pd.read_csv('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/X_test_liter_REINT30.csv')\n",
    "\n",
    "y_train = np.load('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/y_train_liter_REINT30.npy')\n",
    "y_test = np.load('/home/isadoracosenza/Documentos/ebserh-clinical-outcome/notebooks/PREPROCESSED_FILES/reinternacao/reint_first_int_pickles/y_test_liter_REINT30.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba3fbd-d0e3-4bfc-b865-f309e58f883a",
   "metadata": {},
   "source": [
    "Cross Validation com todos os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a6081-5b3a-430a-b8cd-3ed410571f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, zero_division=0),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=7,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy Mean': cv['test_accuracy'].mean(),\n",
    "        'Accuracy Std':  cv['test_accuracy'].std(),\n",
    "        'Precision Mean': cv['test_precision'].mean(),\n",
    "        'Precision Std':  cv['test_precision'].std(),\n",
    "        'Recall Mean': cv['test_recall'].mean(),\n",
    "        'Recall Std':  cv['test_recall'].std(),\n",
    "        'F1 Mean': cv['test_f1'].mean(),\n",
    "        'F1 Std':  cv['test_f1'].std(),\n",
    "        'ROC AUC Mean': cv['test_roc_auc'].mean(),\n",
    "        'ROC AUC Std':  cv['test_roc_auc'].std()\n",
    "    })\n",
    "\n",
    "cross_val = pd.DataFrame(results).round(2)\n",
    "cross_val = cross_val.sort_values(by=\"F1 Mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374e78a-967c-448c-8b5c-089203ca961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val.to_excel('Predictions_CrossVal_liter_REINT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94c5e8-2443-401e-b846-ff54173072b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    trained_models[name] = model  \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_scores = model.decision_function(X_test)\n",
    "        y_prob = expit(y_scores)\n",
    "    else:\n",
    "        y_prob = None\n",
    "        \n",
    "    metrics = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"ROC AUC\": roc_auc_score(y_test, y_prob) if y_prob is not None else None,\n",
    "        \"Specificity\": specificity_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "df_results_test = pd.DataFrame(results).round(2)\n",
    "df_results_sorted = df_results_test.sort_values(by=\"F1 Score\", ascending=False)\n",
    "\n",
    "top5_models = df_results_sorted[\"Model\"].head(5).tolist()\n",
    "\n",
    "for name in top5_models:\n",
    "    model = trained_models[name]\n",
    "    with open(f\"{name}_literature_reint.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"✅ Modelos salvos:\", top5_models)\n",
    "\n",
    "df_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4810d24-824d-411a-ad4b-cdde12e9045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test.to_excel('Predictions_test_liter_REINT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3922cae-9381-4692-8f80-b1d8c2dc90da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = ex.scatter(df_results_test, x='ROC AUC', y='F1 Score', color='Model', title=\"Análise Comparativa (literatura) — Reinternação: F1 score versus ROC AUC score\")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",      # legenda horizontal\n",
    "        yanchor=\"bottom\",\n",
    "        y=-1,               # coloca embaixo\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
